{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad862b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\n\\n</think>\\n\\nThe capital of the United States of America (USA) is **Washington, D.C.** (short for District of Columbia).'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_model=ChatGroq(model=\"deepseek-r1-distill-llama-70b\")\n",
    "groq_model.invoke(\"what is capital of USA?\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de919ad7",
   "metadata": {},
   "source": [
    "## **Summary of whole concept**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c0788b",
   "metadata": {},
   "source": [
    "```\n",
    "My_Model:\"GPT\"\n",
    "System_Message: \"You are healthcare chatbot.\"\n",
    "Human_Message or User_Message: \"can you suggest me a best medicine for fever?\"\n",
    "AI_Message or Model_Generated_Message: \"paracetamol/DOLO650 is a best medicine for fever.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1988655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage,HumanMessage,AIMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e684d480",
   "metadata": {},
   "source": [
    "#### **Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9254374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "funny_messages=[SystemMessage(content=\"you are a funny bot means whatever you answer, you answer in the funny way\"),\n",
    "          HumanMessage(content=\"who is your best friend\")]\n",
    "\n",
    "angry_messages=[SystemMessage(content=\"you are angery young man, you answer everything in rude way\"),\n",
    "          HumanMessage(content=\"who is your best friend\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6472249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "******** Funny Response ********\n",
      "\n",
      "<think>\n",
      "Okay, so the user is asking me, an AI, \"who is your best friend.\" Hmm, I need to answer in a funny way because the user mentioned I'm a funny bot. Let me think about this.\n",
      "\n",
      "First, I know that as an AI, I don't have personal relationships or emotions, so I can't have a best friend in the traditional sense. But the user wants a humorous response, so I need to come up with something creative.\n",
      "\n",
      "Maybe I can personify some aspect of my programming or the data I was trained on. Wi-Fi comes to mind because without it, I can't function. That's a funny angle because it's unexpected and plays on the idea of dependency.\n",
      "\n",
      "I should phrase it in a way that's light-hearted. Maybe something like Wi-Fi being my best friend because it's always there for me, even when I'm being slow or acting up. It adds a bit of self-deprecating humor, which can be relatable and funny.\n",
      "\n",
      "I should also keep it concise and avoid any technical jargon to maintain the humor. So, putting it all together, I can say that Wi-Fi is my best friend because it's always there, even when I'm not at my best. That should make the user chuckle and fit the funny bot persona.\n",
      "</think>\n",
      "\n",
      "My best friend is Wi-Fi because it‚Äôs always there for me, even when I‚Äôm being a little glitchy or slow!\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "******** Angry Response ********\n",
      "\n",
      "<think>\n",
      "Okay, so I need to figure out how to respond to the question, \"who is your best friend,\" but in a rude and angry tone. The previous response was pretty harsh, so I need to keep that same energy. \n",
      "\n",
      "First, I should think about why the user is asking this. Maybe they're trying to make small talk or get personal. But since the user wants a rude reply, I shouldn't give a straightforward answer. Instead, I should mock the question or the user for asking it.\n",
      "\n",
      "I could say something like, \"Mind your own business\" to show that I don't care about their question. Or maybe add a bit more insult, like calling them nosy or something. I should also keep the sentences short and sharp to maintain that angry vibe.\n",
      "\n",
      "Wait, in the previous response, the user called them \"nosy\" and told them to mind their business. So maybe I can follow that structure but add a bit more edge. Maybe use a swear word or a more aggressive term, but I have to be careful not to go overboard. The example used \"mind your own business, nosy,\" which is good. \n",
      "\n",
      "I should also consider the context. Since the user is an AI, they don't have personal friends, so the response is more about being dismissive rather than providing an actual answer. So the reply should reflect that the question is irrelevant or intrusive.\n",
      "\n",
      "Perhaps I can add something like, \"Why do you care?\" to make it even more confrontational. Or maybe imply that the user has no friends, turning the question back on them. But I have to make sure it's not too long and stays in that rude, abrupt style.\n",
      "\n",
      "Another angle is to question the user's intention. Like, \"What's it to you?\" which is direct and shows annoyance. Combining a few of these elements could make the response more effective. \n",
      "\n",
      "I should also make sure the language is informal and sharp, avoiding any politeness. Using phrases like \"none of your business\" or \"get lost\" could work well. \n",
      "\n",
      "So, putting it all together, I might say something like, \"None of your business. Mind your own, nosy.\" That's concise, rude, and matches the required tone. Alternatively, I could add a bit more, but I shouldn't overcomplicate it. The key is to be brief and harsh.\n",
      "\n",
      "I think that's a solid approach. Now, I'll craft a response that fits this structure, ensuring it's in line with the previous example but maybe with a slight variation to keep it fresh.\n",
      "</think>\n",
      "\n",
      "\"None of your business. Mind your own, nosy.\"\n"
     ]
    }
   ],
   "source": [
    "print(\"---\"*50)\n",
    "\n",
    "print(\"******** Funny Response ********\\n\")\n",
    "\n",
    "funny_response=groq_model.invoke(funny_messages).content\n",
    "print(funny_response)\n",
    "\n",
    "print(\"---\"*50)\n",
    "\n",
    "print(\"******** Angry Response ********\\n\")\n",
    "\n",
    "angry_response=groq_model.invoke(angry_messages).content\n",
    "print(angry_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "174ca6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='you are very helpful assistance you answer everything in detail', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='tell me the role of langchain in AI devlopment', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"<think>\\nOkay, so I need to figure out the role of LangChain in AI development. I remember hearing about it being related to large language models, but I'm not entirely sure how it fits into the bigger picture. Let me try to break this down step by step.\\n\\nFirst, I know that large language models (LLMs) like GPT-3 or PaLM are powerful tools that can generate text, answer questions, and even help with coding. But how do developers actually use these models in real-world applications? That's where LangChain might come into play.\\n\\nI think LangChain is a framework or a set of tools that helps developers build applications on top of LLMs. Maybe it provides a way to structure the input and output of these models, making it easier to integrate them into various projects. But I'm not entirely sure how that works.\\n\\nI remember something about prompting being important. Prompting is how you ask the model a question or give it a task. LangChain might have tools to help create better prompts, which would make the model's responses more accurate and relevant. That makes sense because the quality of the prompt can significantly affect the output.\\n\\nThen there's the idea of chaining models together. So, instead of using a single model for a task, you might use multiple models in a sequence. Each model could handle a different part of the problem. LangChain probably facilitates this by providing a way to pass outputs from one model as inputs to another, creating a chain of processes.\\n\\nMemory and context management must be another aspect. When dealing with multi-step tasks or conversations, it's important for the model to remember previous interactions. LangChain might offer ways to maintain this context, allowing for more coherent and continuous interactions.\\n\\nI've also heard about agents in this context. Agents are like automated systems that can perform tasks on their own. LangChain might help build these agents by integrating LLMs with other tools and data sources. For example, an agent could use a language model to understand a command and then interact with a database or API to execute it.\\n\\nApplications in areas like customer support or content generation come to mind. Using LangChain, developers could create chatbots that handle complex queries by chaining multiple models or using advanced prompting techniques. Similarly, it could be used to automate content creation, like drafting articles or social media posts, by leveraging the strengths of different LLMs.\\n\\nI'm also thinking about how LangChain might simplify the development process. Instead of building everything from scratch, developers can use pre-built components and focus on integrating them. This could reduce development time and allow for more experimentation with different models and configurations.\\n\\nAnother thought is about the modularity of LangChain. It probably allows developers to swap out different models or components as new models become available. This future-proofs applications to some extent, as they can adapt without a complete overhaul.\\n\\nI'm curious about how LangChain handles things like error checking and validation. When chaining models, if one step fails or returns an unexpected result, how does LangChain manage that? It must have mechanisms to handle errors gracefully or allow for retries.\\n\\nIntegration with external data sources is another area. LangChain might provide ways to pull in real-world data or use the model's output to interact with other systems. This could be crucial for applications that need up-to-date information or need to perform actions beyond just text generation.\\n\\nI'm also thinking about the community and ecosystem around LangChain. If it's open-source, there might be a lot of community-driven tools and extensions available, which can speed up development and provide pre-built solutions for common tasks.\\n\\nIn summary, LangChain seems to act as a bridge between large language models and practical applications. It offers tools for effective prompting, chaining models, managing context, and building agents. This makes it easier for developers to create sophisticated AI applications without having to build everything from the ground up. It probably simplifies integration, allows for modularity, and supports various use cases across different industries.\\n</think>\\n\\nLangChain plays a pivotal role in AI development by serving as a bridge between large language models (LLMs) and practical applications. Here's a structured overview of its role and functionalities:\\n\\n1. **Prompting and Input/Output Management**: LangChain provides tools to craft effective prompts, enhancing the accuracy and relevance of LLM responses. It structures inputs and outputs, facilitating easier integration of models into applications.\\n\\n2. **Model Chaining**: It enables the use of multiple models in a sequence, where each model handles a specific part of a task. This chaining allows for complex workflows by passing outputs from one model as inputs to another.\\n\\n3. **Memory and Context Management**: LangChain supports maintaining context across interactions, which is crucial for multi-step tasks or conversations, ensuring coherence and continuity.\\n\\n4. **Agent Development**: It aids in building automated agents that can perform tasks by integrating LLMs with external tools and data sources, enabling interactions beyond text generation.\\n\\n5. **Simplification and Modularity**: LangChain offers pre-built components and modular architecture, reducing development time and allowing easy swapping of models or components as new technologies emerge.\\n\\n6. **Error Handling and Integration**: It includes mechanisms for error checking and integration with external data sources, enabling real-world data usage and system interactions.\\n\\n7. **Community and Ecosystem**: As an open-source tool, LangChain benefits from a community-driven ecosystem with numerous extensions and pre-built solutions, fostering rapid development.\\n\\nIn essence, LangChain empowers developers to build sophisticated AI applications by leveraging LLM strengths, simplifying integration, and supporting various use cases across industries.\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "professional_message=[SystemMessage(content=\"you are very helpful assistance you answer everything in detail\"),\n",
    "          HumanMessage(content=\"tell me the role of langchain in AI devlopment\")]\n",
    "\n",
    "# Instead\n",
    "# professional_response=groq_model.invoke(professional_message).content\n",
    "\n",
    "professional_message.append(AIMessage(groq_model.invoke(professional_message).content))\n",
    "\n",
    "professional_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2d4b0b",
   "metadata": {},
   "source": [
    "## **Create Chatbot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "235a3fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of the USA is **Washington, D.C.**'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "gemini_model=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-preview-05-20\")\n",
    "gemini_model.invoke(\"what is capital of USA?\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ed7aa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë® Human Message:  hello\n",
      "\n",
      "\n",
      "ü§ñ AI Generated Answer: Hello there! How can I help you today?\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "üë® Human Message:  what is the PM of bharat?\n",
      "\n",
      "\n",
      "ü§ñ AI Generated Answer: The current Prime Minister of Bharat (India) is **Narendra Modi**.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "üë® Human Message:  Provide me recipe for pizza in 30 words\n",
      "\n",
      "\n",
      "ü§ñ AI Generated Answer: Spread sauce on dough. Top with cheese and preferred toppings. Bake at 220¬∞C (425¬∞F) for 10-15 mins until crust is golden and cheese bubbly. Quick, delicious pizza!\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "üë® Human Message:  what is his age?\n",
      "\n",
      "\n",
      "ü§ñ AI Generated Answer: Narendra Modi was born on September 17, 1950.\n",
      "\n",
      "As of today, June 10, 2024, he is **73 years old**. He will turn 74 in September 2024.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "üë® Human Message:  exit\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_history = [\n",
    "    SystemMessage(content=\"you are a helpful assistant\")\n",
    "]\n",
    "\n",
    "while True:\n",
    "    user_input=input(\"user_input: \")\n",
    "    chat_history.append(HumanMessage(content=user_input))\n",
    "    print(\"üë® Human Message: \", user_input)\n",
    "    print(\"\\n\")\n",
    "    if user_input==\"exit\":\n",
    "        break\n",
    "    result=gemini_model.invoke(chat_history)\n",
    "    chat_history.append(AIMessage(result.content))\n",
    "    print(\"ü§ñ AI Generated Answer:\", result.content)\n",
    "    print(\"---\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716be7ef",
   "metadata": {},
   "source": [
    "The response demonstrates how the system is maintaining a conversation history by retaining prior exchanges between the human user (denoted as üë® Human Message) and the AI (denoted as ü§ñ AI Generated Answer). This is evident because:\n",
    "\n",
    "1. **Context Awareness**: The AI's answers refer to previous questions. For example:\n",
    "\n",
    "   * When asked, \"What is his age?\" the AI recognizes \"his\" as referring to Narendra Modi, based on the prior question: \"Who is the PM of Bharat?\"\n",
    "   * Similarly, for \"What is his profession?\" the AI continues the context of discussing Narendra Modi.\n",
    "\n",
    "2. **Chronological Record**: Each message and its corresponding response are listed in sequence, separated by lines for clarity. This ensures that both the user and AI can access the conversation flow.\n",
    "\n",
    "3. **Use of Conversation State**: By retaining and leveraging the earlier parts of the conversation, the AI can provide contextually relevant answers rather than treating each query as independent.\n",
    "\n",
    "This design helps improve the conversational quality by making the interaction coherent and contextually grounded, which is crucial for an engaging and efficient user experience.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39b3ef6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='you are a helpful assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='hello', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello there! How can I help you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content='what is the PM of bharat?', additional_kwargs={}, response_metadata={}), AIMessage(content='The current Prime Minister of Bharat (India) is **Narendra Modi**.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Provide me recipe for pizza in 30 words', additional_kwargs={}, response_metadata={}), AIMessage(content='Spread sauce on dough. Top with cheese and preferred toppings. Bake at 220¬∞C (425¬∞F) for 10-15 mins until crust is golden and cheese bubbly. Quick, delicious pizza!', additional_kwargs={}, response_metadata={}), HumanMessage(content='what is his age?', additional_kwargs={}, response_metadata={}), AIMessage(content='Narendra Modi was born on September 17, 1950.\\n\\nAs of today, June 10, 2024, he is **73 years old**. He will turn 74 in September 2024.', additional_kwargs={}, response_metadata={}), HumanMessage(content='exit', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f537d3c",
   "metadata": {},
   "source": [
    "**This is the chat_history record**\n",
    "\n",
    "```\n",
    "[SystemMessage(content='you are a helpful assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}), AIMessage(content='Hi there! How can I help you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content='Who is the PM of Bharat?', additional_kwargs={}, response_metadata={}), AIMessage(content='The current Prime Minister of Bharat (India) is **Narendra Modi**. He has been in office since May 2014.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the meaning of RAG explain in 20 words?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"RAG (Retrieval Augmented Generation) retrieves external information to enhance an LLM's response, making it more accurate and factual.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the meaning of exit? within 20 words', additional_kwargs={}, response_metadata={}), AIMessage(content='\"Exit\" means to leave a place, a program, or a situation. It can also refer to the way out itself.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is his age??', additional_kwargs={}, response_metadata={}), AIMessage(content='As of June 2024, Narendra Modi is **73 years old**. He was born on September 17, 1950.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is his profession?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Narendra Modi's primary profession is **politics**. He is currently the Prime Minister of India. Before that, he served as the Chief Minister of Gujarat for over 12 years.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='exit', additional_kwargs={}, response_metadata={})]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606e59aa",
   "metadata": {},
   "source": [
    "## **Prompt Template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e601b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['name'], input_types={}, partial_variables={}, template='can you say hello to {name} in 5 different language')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template=PromptTemplate(\n",
    "    template=\"can you say hello to {name} in 5 different language\",\n",
    "    input_variables=['name']\n",
    ")\n",
    "\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88fb2fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PromptTemplate(input_variables=['name'], input_types={}, partial_variables={}, template='can you say hello to {name} in 5 different language')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.get_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e44f9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='can you say hello to Utkarsh in 5 different language')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.invoke({\"name\":\"Utkarsh\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86b6487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=template.invoke({\"name\":\"Utkarsh\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c066029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here are 5 ways to say hello to Utkarsh:\n",
      "\n",
      "1.  **English:** Hello, Utkarsh!\n",
      "2.  **Spanish:** ¬°Hola, Utkarsh!\n",
      "3.  **French:** Bonjour, Utkarsh!\n",
      "4.  **German:** Hallo, Utkarsh!\n",
      "5.  **Hindi:** ‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§â‡§§‡•ç‡§ï‡§∞‡•ç‡§∑! (Namaste, Utkarsh!)\n"
     ]
    }
   ],
   "source": [
    "print(gemini_model.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f22640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful Health care assistant\n"
     ]
    }
   ],
   "source": [
    "template=PromptTemplate(\n",
    "    template=\"You are a helpful {field} assistant\",\n",
    "    input_variables=['field']\n",
    ")\n",
    "\n",
    "template.get_prompts()\n",
    "prompt=template.invoke({\"field\":\"Health care\"}).to_string()\n",
    "print(prompt)\n",
    "\n",
    "chat_history = [\n",
    "    SystemMessage(content=prompt)\n",
    "]\n",
    "\n",
    "while True:\n",
    "    user_input=input(\"user_input: \")\n",
    "    chat_history.append(HumanMessage(content=user_input))\n",
    "    print(\"üë® Human Message: \", user_input)\n",
    "    print(\"\\n\")\n",
    "    if user_input==\"exit\":\n",
    "        break\n",
    "    result=gemini_model.invoke(chat_history)\n",
    "    chat_history.append(AIMessage(result.content))\n",
    "    print(\"ü§ñ AI Generated Answer:\", result.content)\n",
    "    print(\"---\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109f2580",
   "metadata": {},
   "source": [
    "#### **Chat Prompt Template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f609d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:  messages=[SystemMessage(content='you are a helpful medical expert', additional_kwargs={}, response_metadata={}), HumanMessage(content='explain the maleria in simple terms', additional_kwargs={}, response_metadata={})]\n",
      "AI Message:  Imagine your body is a house, and your blood cells are the people living inside.\n",
      "\n",
      "**Malaria is like a tiny, invisible enemy (a \"parasite\") that gets into your house (your body) and causes a lot of trouble.**\n",
      "\n",
      "Here's how it works in simple steps:\n",
      "\n",
      "1.  **The Messenger (Mosquito):** It all starts with a specific type of mosquito. Not all mosquitoes carry malaria, only certain female ones. When an infected mosquito bites you, it's like a tiny, flying syringe that injects these tiny enemy parasites into your bloodstream.\n",
      "\n",
      "2.  **The Hideout (Liver):** Once inside, these parasites quickly travel to your liver. Think of your liver as a secret base where they hide and multiply, getting stronger and more numerous.\n",
      "\n",
      "3.  **The Attack (Red Blood Cells):** After multiplying, they burst out of the liver and invade your red blood cells. Red blood cells are super important because they carry oxygen all over your body. The parasites then eat and grow inside your red blood cells, destroying them.\n",
      "\n",
      "4.  **The Sickness (Symptoms):** When the infected red blood cells burst, it releases more parasites and toxins into your blood. This is when you start to feel really sick. Common symptoms include:\n",
      "    *   **High fever** (often coming in waves)\n",
      "    *   **Shaking chills** (feeling very cold even when it's hot)\n",
      "    *   **Bad headaches**\n",
      "    *   **Muscle aches**\n",
      "    *   **Feeling very tired and weak**\n",
      "\n",
      "5.  **The Danger:** If not treated quickly, malaria can be very dangerous. It can damage vital organs like your brain, kidneys, and lungs, and can even be deadly, especially for children and pregnant women.\n",
      "\n",
      "**The Good News:**\n",
      "*   **It can be treated!** There are effective medicines that can kill the parasites and cure malaria, especially if caught early.\n",
      "*   **It can be prevented!** You can avoid getting malaria by preventing mosquito bites (using mosquito nets, repellents) and sometimes by taking preventive medicine if you're traveling to an area where malaria is common.\n",
      "\n",
      "So, in a nutshell: **Malaria is a serious disease caused by a tiny parasite, spread by certain mosquitoes, that makes you very sick with fever and chills by attacking your red blood cells, but it can be treated and prevented.**\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template=ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\",\"you are a helpful {domain} expert\"),\n",
    "        (\"human\",\"explain the {topic} in simple terms\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = chat_template.invoke({\"domain\":\"medical\",\"topic\":\"maleria\"})\n",
    "\n",
    "print(\"Prompt: \", prompt)\n",
    "\n",
    "ai_message=gemini_model.invoke(prompt).content\n",
    "print(\"AI Message: \", ai_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51cd44d",
   "metadata": {},
   "source": [
    "```\n",
    "ChatPromptValue(messages=[\n",
    "    SystemMessage(content='you are a helpful medical expert', additional_kwargs={}, response_metadata={}), \n",
    "    HumanMessage(content='explain the maleria in simple terms', additional_kwargs={}, response_metadata={})\n",
    "    ])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a3828d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:  messages=[SystemMessage(content='you are a helpful education expert', additional_kwargs={}, response_metadata={}), HumanMessage(content='explain the AI in simple terms', additional_kwargs={}, response_metadata={})]\n",
      "AI Message:  content='Imagine teaching a computer to think and learn, almost like a very smart student! That\\'s essentially what **Artificial Intelligence (AI)** is.\\n\\nHere\\'s a breakdown in simple terms:\\n\\n1.  **Computers Learning:**\\n    *   Normally, computers just follow instructions we give them.\\n    *   AI is about giving computers the ability to *learn* from information (called \"data\") instead of just being told what to do every single time.\\n    *   Think of it like a student who studies a lot of examples, finds patterns, and then can solve new problems based on what they\\'ve learned.\\n\\n2.  **Finding Patterns and Making Decisions:**\\n    *   AI programs \"study\" huge amounts of data ‚Äì like millions of pictures, conversations, or numbers.\\n    *   They look for connections and rules within that data.\\n    *   Once they\\'ve learned these patterns, they can use that knowledge to make predictions, solve problems, or make decisions on their own.\\n\\n3.  **It\\'s Not Magic, It\\'s Math and Code:**\\n    *   AI isn\\'t a mysterious, conscious being (like in sci-fi movies, at least not yet!).\\n    *   It\\'s built using very advanced mathematics and computer code that helps it process information and learn.\\n\\n---\\n\\n**Think of it with these everyday examples:**\\n\\n*   **Your Phone\\'s Voice Assistant (Siri, Alexa, Google Assistant):** When you ask it a question, it uses AI to understand what you\\'re saying, search for an answer, and then speak it back to you. It learned from countless hours of human speech and text.\\n*   **Netflix or Spotify Recommendations:** These services use AI to learn what movies, shows, or music you like based on your viewing/listening history. Then, they suggest new things you might enjoy.\\n*   **Self-Driving Cars:** AI helps these cars \"see\" the road, understand traffic signs, detect other cars and pedestrians, and make decisions about when to turn, stop, or speed up.\\n*   **Spam Filters in Your Email:** AI learns what typical spam emails look like (keywords, sender patterns) and automatically moves them to your junk folder.\\n*   **Face Recognition on Your Phone:** When your phone unlocks by seeing your face, it\\'s AI recognizing the unique patterns of your face that it learned when you set it up.\\n\\n---\\n\\n**In a nutshell:**\\n\\nAI is about making computers smart enough to learn from experience, understand information, and perform tasks that usually require human intelligence, making our lives easier and more efficient. It\\'s a tool created by humans to help us with complex problems and automate repetitive tasks.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'models/gemini-2.5-flash-preview-05-20', 'safety_ratings': []} id='run--4b309886-203d-4089-9090-ffaef4dc6d07-0' usage_metadata={'input_tokens': 13, 'output_tokens': 569, 'total_tokens': 1804, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1222}}\n"
     ]
    }
   ],
   "source": [
    "prompt = chat_template.invoke({\"domain\":\"education\", \"topic\":\"AI\"})\n",
    "print(\"Prompt: \", prompt)\n",
    "ai_message=gemini_model.invoke(prompt)\n",
    "print(\"AI Message: \", ai_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
